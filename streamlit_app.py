import streamlit as st
import os
import sys
import gdown
from tensorflow.keras.models import load_model
import numpy as np

# 1. ConfiguraciÃ³n de rutas compatible con Streamlit Cloud
MODEL_URL = "https://drive.google.com/uc?id=13S8aXIDQpixM5Siy-0tWHSm2MEHw1Ksh"
MODEL_NAME = "my_model.keras"
MODEL_PATH = os.path.join(os.getcwd(), MODEL_NAME)  # Ruta absoluta en el directorio de trabajo actual

# 2. FunciÃ³n de descarga robusta
def download_model():
    if os.path.exists(MODEL_PATH):
        st.warning("âš ï¸ El modelo ya existe. Borrando antes de redescargar...")
        os.remove(MODEL_PATH)
    
    try:
        with st.spinner(f"Descargando modelo (310MB) desde Google Drive..."):
            gdown.download(MODEL_URL, MODEL_PATH, quiet=False)
        
        if os.path.exists(MODEL_PATH):
            file_size = os.path.getsize(MODEL_PATH) / (1024 * 1024)
            if file_size > 300:  # Verifica que el tamaÃ±o sea >300MB
                st.success(f"âœ… Descarga exitosa! TamaÃ±o: {file_size:.1f}MB")
                return True
            else:
                st.error(f"âŒ Archivo demasiado pequeÃ±o ({file_size:.1f}MB). Â¿Descarga corrupta?")
        else:
            st.error("âŒ El archivo no se creÃ³ correctamente")
        return False
    except Exception as e:
        st.error(f"âŒ Error en descarga: {str(e)}")
        return False

# 3. VerificaciÃ³n de ubicaciÃ³n REAL del archivo
def debug_file_location():
    st.subheader("ğŸ” Debug: UbicaciÃ³n Real")
    st.write(f"**Directorio actual:** `{os.getcwd()}`")
    st.write(f"**Archivos presentes:** `{os.listdir()}`")
    st.write(f"**Ruta esperada del modelo:** `{MODEL_PATH}`")
    if os.path.exists(MODEL_PATH):
        st.success(f"âœ”ï¸ El modelo SÃ existe en la ruta esperada")
    else:
        st.error(f"âœ–ï¸ El modelo NO estÃ¡ en la ruta esperada")

# Interfaz principal
st.title("ğŸ”§ Cargador de Modelos Grandes (310MB)")

# --- SecciÃ³n de Descarga ---
st.header("1. Descargar Modelo")
if st.button("â¬‡ï¸ Descargar Modelo"):
    if download_model():
        st.balloons()

# --- SecciÃ³n de Debug --- 
debug_file_location()

# --- SecciÃ³n de Carga ---
st.header("2. Cargar Modelo")
if os.path.exists(MODEL_PATH):
    try:
        with st.spinner("Cargando modelo..."):
            model = load_model(MODEL_PATH)
            st.success("âœ… Â¡Modelo cargado correctamente!")
            
            # Test de predicciÃ³n
            dummy_input = np.random.rand(*model.input_shape[1:]).astype(np.float32)
            prediction = model.predict(np.expand_dims(dummy_input, axis=0))
            st.success(f"ğŸ‰ Â¡PredicciÃ³n exitosa! Forma del output: {prediction.shape}")
            
    except Exception as e:
        st.error(f"âŒ Error al cargar: {str(e)}")
        st.markdown("""
        **Soluciones comunes:**
        1. Verifica que el archivo sea un modelo Keras vÃ¡lido
        2. Revisa la compatibilidad de versiones de TensorFlow
        3. Usa el debug para confirmar la ubicaciÃ³n real
        """)
else:
    st.warning("âš ï¸ Primero descarga el modelo")

# --- Reset ---
if st.button("ğŸ”„ Reiniciar Todo"):
    if os.path.exists(MODEL_PATH):
        os.remove(MODEL_PATH)
    st.success("Â¡Entorno reiniciado!")
